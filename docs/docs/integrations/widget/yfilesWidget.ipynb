{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd4c8510-d8c6-41f4-9c22-703cb7c52d85",
   "metadata": {},
   "source": [
    "# Yfiles Jupyter Graphs Widget\n",
    "\n",
    "This widget is able to visualize the runnables from the langchain-core package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7292050-8055-4bda-a1a4-7d0a4ab59a68",
   "metadata": {},
   "source": [
    "## Create a basic graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e8972-1976-42d7-8760-d22b881785a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langsmith\n",
    "from langchain_community.widgets import YfilesJupyterWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329bc92-e4ce-47d6-8735-4605043f5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Literal\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7fbe3-51d3-4280-9f49-0f38075ce3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abec80f-adf7-43a1-851e-6915797cff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder, but don't tell the LLM that...\n",
    "    return [\"Cloudy with a chance of hail.\"]\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273797b-4e9b-4df1-982d-93465806293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f193-cfa6-4aa1-8773-07ae67ab2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: State) -> Literal[\"__end__\", \"tools\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"tools\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "async def call_model(state: State, config: RunnableConfig):\n",
    "    messages = state[\"messages\"]\n",
    "    # Note: Passing the config through explicitly is required for python < 3.11\n",
    "    # Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks\n",
    "    response = await model.ainvoke(messages, config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d355dc0-2a2f-41f2-bce5-17ef271f6823",
   "metadata": {},
   "source": [
    "## Widget visualization\n",
    "\n",
    "\n",
    "To actually use the widget, simply call the `show_jupyter_widget` funtion with your Runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6e0a8-173c-4459-a83e-8c3db4be20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfiles_jupyter_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17069a-d3d0-47f5-8ec4-88e13a61e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = YfilesJupyterWidget()\n",
    "w.show_jupyter_widget(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
