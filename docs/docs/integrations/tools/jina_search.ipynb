{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jina Search\n",
    "\n",
    "This notebook goes over how to use the Jina Search tool.\n",
    "Go to the [Jina Website](https://jina.ai) for more information about Jina AI and their offerings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import JinaSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = JinaSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"title\": \"LangChain\", \"link\": \"https://www.langchain.com/\", \"snippet\": \"<strong>LangChain</strong>\\\\u2019s suite of products supports developers along each step of their development journey.\", \"content\": \"From startups to global enterprises,  \\\\nambitious builders choose  \\\\nLangChain products.\\\\n--------------------------------------------------------------------------------------\\\\n\\\\n![Image 1](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c22746faa78338532_logo_Ally.svg)![Image 2](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c08e67bb7eefba4c2_logo_Rakuten.svg)![Image 3](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c576fdde32d03c1a0_logo_Elastic.svg)![Image 4](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c6d5592036dae24e5_logo_BCG.svg)![Image 5](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6651232f52288a15729f1654_streamlit-logo-B405F7E2FC-seeklogo.com.png)![Image 6](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7cbcf6473519b06d84_logo_IDEO.svg)![Image 7](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7cb5f96dcc100ee3b7_logo_Zapier.svg)![Image 8](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6606183e52d49bc369acc76c_mdy_logo_rgb_moodysblue.png)![Image 9](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c8ad7db6ed6ec611e_logo_Adyen.svg)![Image 10](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c737d50036a62768b_logo_Infor.svg)![Image 11](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66537f852a8efa455eb81c40_image%201%20(2).png)![Image 12](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c09a158ffeaab0bd2_logo_Replit.svg)![Image 13](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c9d2b23d292a0cab0_logo_Retool.svg)![Image 14](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c44e67a3d0a996bf3_logo_Databricks.svg)![Image 15](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c1c250c0c8485be44_logo_Snowflake.svg)![Image 16](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ca3b7c63af578816bafcc3_logo_Instacart.svg)![Image 17](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/665dc1dabc940168384d9596_podium%20logo.svg)\\\\n\\\\nBuild\\\\n\\\\nLangChain gives developers a\\\\u00a0framework to construct LLM**\\\\u2011**powered apps easily.\\\\n\\\\nObserve\\\\n\\\\nLangSmith gives visibility into what\\\\u2019s happening with\\\\u00a0your LLM-powered app, whether it\\'s built with LangChain or not, so you know how to take action and\\\\u00a0improve quality.\\\\n\\\\nDeploy\\\\n\\\\nLangServe makes serving an API for  \\\\nyour LangChain application turnkey.\\\\n\\\\nBuild your app with LangChain\\\\n-----------------------------\\\\n\\\\nBuild context-aware, reasoning applications with LangChain\\\\u2019s flexible framework that leverages your company\\\\u2019s data and APIs. Future-proof your application by making vendor optionality part of your LLM infrastructure design.\\\\n\\\\n[Learn more about LangChain](https://www.langchain.com/langchain)\\\\n\\\\nObserve performance with\\\\u00a0LangSmith\\\\n----------------------------------\\\\n\\\\nShip faster with LangSmith\\\\u2019s debug, test, deploy, and monitoring workflows. Don\\\\u2019t rely on \\\\u201cvibes\\\\u201d \\\\u2013 add engineering rigor to your LLM-development workflow, whether you\\\\u2019re building with LangChain or not.\\\\n\\\\n[Learn more about LangSmith](https://www.langchain.com/langsmith)\\\\n\\\\n![Image 18](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c7d6602bfec259279d8f39_langserve-product-image-1-home.png)![Image 19](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c7d660fd204fb45bbcdb4c_langserve-product-image-2-home.png)\\\\n\\\\nInstantly deploy with LangServe\\\\n-------------------------------\\\\n\\\\nEasily deploy your LangChain application with LangServe, with built in parallelization, fallbacks, batch, streaming, and async support for your API endpoints.\\\\n\\\\n[Learn more about LangServe](https://python.langchain.com/v0.2/docs/langserve/)\\\\n\\\\n### Hear from our happy customers\\\\n\\\\nLangSmith helps teams of all sizes, across all industries, from ambitious \\\\u2028startups to established enterprises.\\\\n\\\\nThe reference architecture enterprises adopt for success.\\\\n---------------------------------------------------------\\\\n\\\\nLangChain\\'s suite of products easily stack together for ease of set up and multiplicative impact.\\\\n\\\\n![Image 20](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65d3f0f1c87222dae11ba6c5_LC%20stack%20-%20FOR%20WEBSITE%20-%201x.png)![Image 21](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65d3f0f1c87222dae11ba6c5_LC%20stack%20-%20FOR%20WEBSITE%20-%201x.png)\\\\n\\\\nGet started with the LangSmith platform today\\\\n---------------------------------------------\\\\n\\\\n![Image 22](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65ccf12801bc39bf912a58f3_Home%20C.webp)\\\\n\\\\nGain visibility to make trade offs between cost, latency, and quality.\\\\n\\\\nIncrease developer productivity.\\\\n\\\\nEliminate manual, error-prone testing.\\\\n\\\\nReduce hallucinations and improve reliability.\\\\n\\\\nEnterprise deployment options to keep data secure.\\\\n\\\\nReady to start shipping \\\\u2028reliable GenAI apps faster?\\\\n----------------------------------------------------\\\\n\\\\nLangChain and LangSmith are critical parts of the reference \\\\u2028architecture to get you from prototype to production.\"}, {\"title\": \"LangChain\", \"link\": \"https://www.techtarget.com/searchenterpriseai/definition/LangChain\", \"snippet\": \"LangChain is <strong>a framework that simplifies the process of creating generative AI application interfaces</strong>. Developers working on these types of interfaces use various tools to create advanced NLP apps; LangChain streamlines this process. For example, LLMs have to access large volumes of big data, ...\", \"content\": \"What is LangChain?\\\\n------------------\\\\n\\\\nLangChain is an open source framework that lets software developers working with artificial intelligence (AI) and its machine learning subset combine large language models with other external components to develop [LLM](https://www.techtarget.com/whatis/definition/large-language-model-LLM)\\\\\\\\-powered applications. The goal of LangChain is to link powerful LLMs, such as OpenAI\\'s GPT-3.5 and [GPT-4](https://www.techtarget.com/whatis/definition/GPT-4), to an array of external data sources to create and reap the benefits of natural language processing ([NLP](https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP)) applications.\\\\n\\\\nDevelopers, software engineers and data scientists with experience in the Python, JavaScript or TypeScript programming languages can make use of LangChain\\'s packages offered in those languages. LangChain was launched as an open source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year.\\\\n\\\\nWhy is LangChain important?\\\\n---------------------------\\\\n\\\\nLangChain is a framework that simplifies the process of creating [generative AI](https://www.techtarget.com/searchenterpriseai/definition/generative-AI) application interfaces. Developers working on these types of interfaces use various tools to create advanced NLP apps; LangChain streamlines this process. For example, LLMs have to access large volumes of [big data](https://www.techtarget.com/searchdatamanagement/definition/big-data), so LangChain organizes these large quantities of data so that they can be accessed with ease.\\\\n\\\\nIn addition, [GPT (Generative Pre-trained Transformer) models](https://www.techtarget.com/searchenterpriseai/feature/ChatGPT-vs-GPT-How-are-they-different) are generally trained on data up to their release to the public. For instance, [ChatGPT](https://www.techtarget.com/whatis/definition/ChatGPT) was released to the public near the end of 2022, but its knowledge base was limited to data from 2021 and before. LangChain can connect AI models to data sources to give them knowledge of recent data without limitations.\\\\n\\\\nWhat are the features of LangChain?\\\\n-----------------------------------\\\\n\\\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\\\n\\\\n*   **Model interaction.** Also called model I/O, this module lets LangChain interact with any language model and perform tasks such as managing inputs to the model and extracting information from its outputs.\\\\n*   **Data connection and retrieval.** Data that LLMs access can be transformed, stored in databases and retrieved from those databases through queries with this module.\\\\n*   **Chains.** When using LangChain to build more complex apps, other components or even more than one LLM might be required. This module links multiple LLMs with other components or LLMs. This is referred to as an LLM chain.\\\\n*   **Agents.** The agent module lets LLMs decide the best steps or actions to take to solve problems. It does so by orchestrating a series of complex commands to LLMs and other tools to get them to respond to specific requests.\\\\n*   **Memory.** The memory module helps an LLM remember the context of its interactions with users. Both short-term memory and long-term memory can be added to a model, depending on the specific use.\\\\n\\\\nWhat are the integrations of LangChain?\\\\n---------------------------------------\\\\n\\\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. For example, LangChain can build [chatbots](https://www.techtarget.com/searchcustomerexperience/infographic/The-evolution-of-chatbots-and-generative-AI) or question-answering systems by integrating an LLM -- such as those from Hugging Face, Cohere and OpenAI -- with data sources or stores such as Apify Actors, Google Search and Wikipedia. This enables an app to take user-input text, process it and retrieve the best answers from any of these sources. In this sense, LangChain integrations make use of the most up-to-date NLP technology to build effective apps.\\\\n\\\\nOther potential integrations include cloud storage platforms, such as Amazon Web Services, Google Cloud and Microsoft Azure, as well as vector databases. A vector database can store large volumes of high-dimensional data -- such as videos, images and long-form text -- as mathematical representations that make it easier for an application to query and search for those data elements. Pinecone is [an example](https://www.pinecone.io/company/) vector database that can be integrated with LangChain.\\\\n\\\\n![Image 1: Steps showing how a LangChain app works.](https://cdn.ttgtmedia.com/rms/onlineimages/a_langchain_app_in_its_most_basic_form-f_mobile.png)\\\\n\\\\nLangChain augments existing large language models so that they are equipped to handle user queries and prompts.\\\\n\\\\nHow to create prompts in LangChain\\\\n----------------------------------\\\\n\\\\nPrompts serve as input to the LLM that instructs it to return a response, which is often an answer to a query. This response is also referred to as an output. A [prompt](https://www.techtarget.com/searchenterpriseai/definition/AI-prompt) must be designed and executed correctly to increase the likelihood of a well-written and accurate response from a language model. That is why [prompt engineering is an emerging science](https://www.techtarget.com/whatis/feature/Skills-needed-to-become-a-prompt-engineer) that has received more attention in recent years.\\\\n\\\\nPrompts can be generated easily in LangChain implementations using a prompt template, which will be used as instructions for the underlying LLM. Prompt templates can vary in specificity. They can be designed to pose simple questions to a language model. They can also be used to provide a set of explicit instructions to a language model with enough detail and examples to retrieve a high-quality response.\\\\n\\\\nWith Python programming, LangChain has a premade prompt template that takes the form of structured text. The following steps are required to use this:\\\\n\\\\n*   **Installing Python.** A recent version of Python must be installed. Once the Python [shell](https://www.techtarget.com/searchdatacenter/definition/shell-script) terminal is open, enter the following command to install just the bare minimum requirements of LangChain for the sake of this example.\\\\n\\\\npip install langchain\\\\n\\\\n*   **Adding integrations.** LangChain typically requires at least one integration. OpenAI is a prime example. To use OpenAI\\'s LLM application programming interfaces, a developer must create an account on the OpenAI website and retrieve the [API](https://www.techtarget.com/searchapparchitecture/definition/application-program-interface-API) access key. Then, using the following code snippet, install OpenAI\\'s Python package and enter the key for access to the APIs.\\\\n\\\\npip install openai  \\\\nfrom langchain.llms import OpenAI  \\\\nllm = OpenAI(openai\\\\\\\\_api\\\\\\\\_key=\\\\\"...\\\\\")\\\\n\\\\n*   **Importing the prompt template.** Once these basic steps are complete, LangChain\\'s prompt template method must then be imported. The code snippet shown below does this.\\\\n\\\\nfrom langchain import PromptTemplate  \\\\nprompt\\\\\\\\_template = PromptTemplate.from\\\\\\\\_template(  \\\\n    \\\\\"Tell me an {adjective} fact about {content}.\\\\\"  \\\\n)  \\\\nprompt\\\\\\\\_template.format(adjective=\\\\\"interesting\\\\\", content=\\\\\"zebras\\\\\")  \\\\n\\\\\"Tell me an interesting fact about zebras.\\\\\"\\\\n\\\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\\\n\\\\nHow to develop applications in LangChain\\\\n----------------------------------------\\\\n\\\\nLangChain is built to develop apps powered by language model functionality. There are different ways to do this, but the process typically entails some key steps:\\\\n\\\\n*   **Define the application.** An application developer must first define a specific use case for the application. This also means determining its scope, including requirements such as any needed integrations, components and LLMs.\\\\n*   **Build functionality.** Developers use prompts to build the functionality or logic of the intended app.\\\\n*   **Customize functionality.** LangChain lets developers modify its code to create customized functionality that meets the needs of the use case and shapes the application\\'s behavior.\\\\n*   **Fine-tuning LLMs.** It\\'s important to choose the appropriate LLM for the job and also to fine-tune it to adhere to the needs of the use case.\\\\n*   **Data cleansing.** Using [data cleansing](https://www.techtarget.com/searchdatamanagement/definition/data-scrubbing) techniques ensures clean and accurate data sets. Also, security measures should be implemented to protect sensitive data.\\\\n*   **Testing.** Regularly testing LangChain apps ensures they continue to run smoothly.\\\\n\\\\nExamples and use cases for LangChain\\\\n------------------------------------\\\\n\\\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\\\n\\\\n*   **Customer service chatbots.** The most obvious use case would be customer support chatbots. LangChain enables chat applications that are advanced enough to handle complex questions and even transactions from users. These applications are able to understand and maintain a user\\'s context throughout a conversation in the same way ChatGPT can. AI is already being widely used to [enhance customer experience and service](https://www.techtarget.com/searchcustomerexperience/post/How-AI-can-benefit-CX-and-customer-service).\\\\n*   **Coding assistants.** It\\'s possible to build coding assistants with the help of LangChain. Using LangChain and OpenAI\\'s API, developers can create a tool to assist those in the tech sector with enhancing their coding skills and improving productivity.\\\\n*   **Healthcare.** [AI has made its way into healthcare](https://www.techtarget.com/searchenterpriseai/feature/How-AI-has-cemented-its-role-in-telemedicine) in several ways. LLM-centric LangChain applications are helping doctors make diagnoses. They\\'re also automating rote, repetitive administrative tasks, such as scheduling patient appointments, enabling healthcare workers to focus on more important work.\\\\n*   **Marketing and e-commerce.** Businesses use e-commerce platforms with LLM functionality to better engage customers and expand their customer base. An application that can understand consumer purchasing patterns and product descriptions can generate product recommendations and compelling descriptions for potential customers.\\\\n\\\\n_Reaping the benefits of NLP is a key of why LangChain is important. For a more in-depth understanding of NLP, there are two important subtopics to start with: natural language understanding ([NLU](https://www.techtarget.com/searchenterpriseai/definition/natural-language-understanding-NLU)) and natural language generation ([NLG](https://www.techtarget.com/searchenterpriseai/definition/natural-language-generation-NLG)). The goal of NLU is to process a user\\'s intended meaning, while the goal of NLG is to explain an AI system\\'s structured data in human-readable languages for humans to comprehend._\\\\n\\\\nThis was last updated in September 2023\\\\n\\\\n#### Continue Reading About LangChain\\\\n\\\\n*   [Prompt engineering vs. fine-tuning: What\\'s the difference?](https://www.techtarget.com/searchenterpriseai/tip/Prompt-engineering-vs-fine-tuning-Whats-the-difference)\\\\n\\\\n*   [The best large language models](https://www.techtarget.com/whatis/feature/12-of-the-best-large-language-models)\\\\n\\\\n*   [Assessing the environmental impact of large language models](https://www.techtarget.com/searchenterpriseai/tip/Assessing-the-environmental-impact-of-large-language-models)\\\\n\\\\n*   [AI groups work to tune, release large language models](https://www.techtarget.com/searchenterpriseai/news/252526387/AI-groups-work-to-tune-release-large-language-models)\\\\n\\\\n*   [Assessing different types of generative AI applications](https://www.techtarget.com/searchenterpriseai/tip/Assessing-different-types-of-generative-AI-applications)\\\\n\\\\n#### Dig Deeper on AI technologies\\\\n\\\\n*   [![Image 2](https://cdn.ttgtmedia.com/visuals/digdeeper/1.jpg) ##### What are large language models (LLMs)? ![Image 3: SeanKerner](https://cdn.ttgtmedia.com/rms/onlineImages/kerner_sean.jpg) By: Sean Kerner](https://www.techtarget.com/whatis/definition/large-language-model-LLM)\\\\n*   [![Image 4](https://cdn.ttgtmedia.com/rms/onlineimages/keys_a408418016_searchsitetablet_520X173.jpg) ##### Amazon Bedrock users adapt app dev to GenAI ![Image 5: BethPariseau](https://cdn.ttgtmedia.com/rms/onlineimages/pariseau_beth.jpg) By: Beth Pariseau](https://www.techtarget.com/searchsoftwarequality/news/366583192/Amazon-Bedrock-users-adapt-app-dev-to-GenAI)\\\\n*   [![Image 6](https://cdn.ttgtmedia.com/rms/onlineimages/chatbot_g1196309272_searchsitetablet_520X173.jpg) ##### Claude AI vs. ChatGPT: How do they compare? ![Image 7: LevCraig](https://cdn.ttgtmedia.com/rms/onlineimages/craig_lev.jpg) By: Lev Craig](https://www.techtarget.com/searchenterpriseai/feature/Claude-AI-vs-ChatGPT-How-do-they-compare)\\\\n*   [![Image 8](https://cdn.ttgtmedia.com/rms/onlineimages/arvr_g1273484747_searchsitetablet_520X173.jpg) ##### How to build an enterprise generative AI tech stack ![Image 9: Kashyap Kompella](https://cdn.ttgtmedia.com/rms/onlineimages/kompella_kashyap.jpg) By: Kashyap Kompella](https://www.techtarget.com/searchenterpriseai/tip/How-to-build-an-enterprise-generative-AI-tech-stack)\"}, {\"title\": \"Introduction | \\\\ud83e\\\\udd9c\\\\ufe0f\\\\ud83d\\\\udd17 LangChain\", \"link\": \"https://python.langchain.com/v0.2/docs/introduction/\", \"snippet\": \"LangChain 0.2 is out! Leave feedback on the v0.2 docs here. You can view the v0.1 docs here. ... LangChain is <strong>a framework for developing applications powered by large language models (LLMs).</strong>\", \"content\": \"Introduction | \\\\ud83e\\\\udd9c\\\\ufe0f\\\\ud83d\\\\udd17 LangChain\\\\n===============\\\\n     \\\\n\\\\n[Skip to main content](https://python.langchain.com/v0.2/docs/introduction/#__docusaurus_skipToContent_fallback)\\\\n\\\\nLangChain 0.2 is out! Leave feedback on the v0.2 docs [here](https://github.com/langchain-ai/langchain/discussions/21716). You can view the v0.1 docs [here](https://python.langchain.com/v0.1/docs/get_started/introduction/).\\\\n\\\\n[![Image 1: \\\\ud83e\\\\udd9c\\\\ufe0f\\\\ud83d\\\\udd17 LangChain](https://python.langchain.com/v0.2/img/brand/wordmark.png)](https://python.langchain.com/v0.2/)[Integrations](https://python.langchain.com/v0.2/docs/integrations/platforms/)[API Reference](https://api.python.langchain.com/)\\\\n\\\\n[More](https://python.langchain.com/v0.2/docs/introduction/#)\\\\n\\\\n*   [People](https://python.langchain.com/v0.2/docs/people/)\\\\n*   [Contributing](https://python.langchain.com/v0.2/docs/contributing/)\\\\n*   [Templates](https://python.langchain.com/v0.2/docs/templates/)\\\\n*   [Cookbooks](https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md)\\\\n*   [3rd party tutorials](https://python.langchain.com/v0.2/docs/additional_resources/tutorials/)\\\\n*   [YouTube](https://python.langchain.com/v0.2/docs/additional_resources/youtube/)\\\\n*   [arXiv](https://python.langchain.com/v0.2/docs/additional_resources/arxiv_references/)\\\\n\\\\n[v0.2](https://python.langchain.com/v0.2/docs/introduction/#)\\\\n\\\\n*   [v0.2](https://python.langchain.com/v0.2/docs/introduction/)\\\\n*   [v0.1](https://python.langchain.com/v0.1/docs/get_started/introduction)\\\\n\\\\n[\\\\ud83e\\\\udd9c\\\\ufe0f\\\\ud83d\\\\udd17](https://python.langchain.com/v0.2/docs/introduction/#)\\\\n\\\\n*   [LangSmith](https://smith.langchain.com/)\\\\n*   [LangSmith Docs](https://docs.smith.langchain.com/)\\\\n*   [LangServe GitHub](https://github.com/langchain-ai/langserve)\\\\n*   [Templates GitHub](https://github.com/langchain-ai/langchain/tree/master/templates)\\\\n*   [Templates Hub](https://templates.langchain.com/)\\\\n*   [LangChain Hub](https://smith.langchain.com/hub)\\\\n*   [JS/TS Docs](https://js.langchain.com/)\\\\n\\\\n[\\\\ud83d\\\\udcac](https://chat.langchain.com/)[](https://github.com/langchain-ai/langchain)\\\\n\\\\nSearchK\\\\n\\\\n*   [Introduction](https://python.langchain.com/v0.2/docs/introduction/)\\\\n*   [Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\\\\n    \\\\n    *   [Build a Question Answering application over a Graph Database](https://python.langchain.com/v0.2/docs/tutorials/graph/)\\\\n    *   [Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\\\\n    *   [Build a Simple LLM Application with LCEL](https://python.langchain.com/v0.2/docs/tutorials/llm_chain/)\\\\n    *   [Build a Query Analysis System](https://python.langchain.com/v0.2/docs/tutorials/query_analysis/)\\\\n    *   [Build a Chatbot](https://python.langchain.com/v0.2/docs/tutorials/chatbot/)\\\\n    *   [Conversational RAG](https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/)\\\\n    *   [Build an Extraction Chain](https://python.langchain.com/v0.2/docs/tutorials/extraction/)\\\\n    *   [Build an Agent](https://python.langchain.com/v0.2/docs/tutorials/agents/)\\\\n    *   [Tagging](https://python.langchain.com/v0.2/docs/tutorials/classification/)\\\\n    *   [data\\\\\\\\_generation](https://python.langchain.com/v0.2/docs/tutorials/data_generation/)\\\\n    *   [Build a Local RAG Application](https://python.langchain.com/v0.2/docs/tutorials/local_rag/)\\\\n    *   [Build a PDF ingestion and Question/Answering system](https://python.langchain.com/v0.2/docs/tutorials/pdf_qa/)\\\\n    *   [Build a Retrieval Augmented Generation (RAG) App](https://python.langchain.com/v0.2/docs/tutorials/rag/)\\\\n    *   [Vector stores and retrievers](https://python.langchain.com/v0.2/docs/tutorials/retrievers/)\\\\n    *   [Build a Question/Answering system over SQL data](https://python.langchain.com/v0.2/docs/tutorials/sql_qa/)\\\\n    *   [Summarize Text](https://python.langchain.com/v0.2/docs/tutorials/summarization/)\\\\n*   [How-to guides](https://python.langchain.com/v0.2/docs/how_to/)\\\\n    \\\\n    *   [How-to guides](https://python.langchain.com/v0.2/docs/how_to/)\\\\n    *   [How to use tools in a chain](https://python.langchain.com/v0.2/docs/how_to/tools_chain/)\\\\n    *   [How to use a vectorstore as a retriever](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/)\\\\n    *   [How to add memory to chatbots](https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/)\\\\n    *   [How to use example selectors](https://python.langchain.com/v0.2/docs/how_to/example_selectors/)\\\\n    *   [How to map values to a graph database](https://python.langchain.com/v0.2/docs/how_to/graph_mapping/)\\\\n    *   [How to add a semantic layer over graph database](https://python.langchain.com/v0.2/docs/how_to/graph_semantic/)\\\\n    *   [How to invoke runnables in parallel](https://python.langchain.com/v0.2/docs/how_to/parallel/)\\\\n    *   [How to stream chat model responses](https://python.langchain.com/v0.2/docs/how_to/chat_streaming/)\\\\n    *   [How to add default invocation args to a Runnable](https://python.langchain.com/v0.2/docs/how_to/binding/)\\\\n    *   [How to add retrieval to chatbots](https://python.langchain.com/v0.2/docs/how_to/chatbots_retrieval/)\\\\n    *   [How to use few shot examples in chat models](https://python.langchain.com/v0.2/docs/how_to/few_shot_examples_chat/)\\\\n    *   [How to do tool/function calling](https://python.langchain.com/v0.2/docs/how_to/function_calling/)\\\\n    *   [How to best prompt for Graph-RAG](https://python.langchain.com/v0.2/docs/how_to/graph_prompting/)\\\\n    *   [Installation](https://python.langchain.com/v0.2/docs/how_to/installation/)\\\\n    *   [How to add examples to the prompt for query analysis](https://python.langchain.com/v0.2/docs/how_to/query_few_shot/)\\\\n    *   [How to add tools to chatbots](https://python.langchain.com/v0.2/docs/how_to/chatbots_tools/)\\\\n    *   [How to use few shot examples](https://python.langchain.com/v0.2/docs/how_to/few_shot_examples/)\\\\n    *   [How to run custom functions](https://python.langchain.com/v0.2/docs/how_to/functions/)\\\\n    *   [How to use output parsers to parse an LLM response into structured format](https://python.langchain.com/v0.2/docs/how_to/output_parser_structured/)\\\\n    *   [How to handle cases where no queries are generated](https://python.langchain.com/v0.2/docs/how_to/query_no_queries/)\\\\n    *   [How to route between sub-chains](https://python.langchain.com/v0.2/docs/how_to/routing/)\\\\n    *   [How to return structured data from a model](https://python.langchain.com/v0.2/docs/how_to/structured_output/)\\\\n    *   [How to use toolkits](https://python.langchain.com/v0.2/docs/how_to/toolkits/)\\\\n    *   [How to add ad-hoc tool calling capability to LLMs and Chat Models](https://python.langchain.com/v0.2/docs/how_to/tools_prompting/)\\\\n    *   [Build an Agent with AgentExecutor (Legacy)](https://python.langchain.com/v0.2/docs/how_to/agent_executor/)\\\\n    *   [How to construct knowledge graphs](https://python.langchain.com/v0.2/docs/how_to/graph_constructing/)\\\\n    *   [How to partially format prompt templates](https://python.langchain.com/v0.2/docs/how_to/prompts_partial/)\\\\n    *   [How to handle multiple queries when doing query analysis](https://python.langchain.com/v0.2/docs/how_to/query_multiple_queries/)\\\\n    *   [How to use built-in tools and toolkits](https://python.langchain.com/v0.2/docs/how_to/tools_builtin/)\\\\n    *   [How to pass through arguments from one step to the next](https://python.langchain.com/v0.2/docs/how_to/passthrough/)\\\\n    *   [How to compose prompts together](https://python.langchain.com/v0.2/docs/how_to/prompts_composition/)\\\\n    *   [How to handle multiple retrievers when doing query analysis](https://python.langchain.com/v0.2/docs/how_to/query_multiple_retrievers/)\\\\n    *   [How to add values to a chain\\'s state](https://python.langchain.com/v0.2/docs/how_to/assign/)\\\\n    *   [How to construct filters for query analysis](https://python.langchain.com/v0.2/docs/how_to/query_constructing_filters/)\\\\n    *   [How to configure runtime chain internals](https://python.langchain.com/v0.2/docs/how_to/configure/)\\\\n    *   [How deal with high cardinality categoricals when doing query analysis](https://python.langchain.com/v0.2/docs/how_to/query_high_cardinality/)\\\\n    *   [Custom Document Loader](https://python.langchain.com/v0.2/docs/how_to/document_loader_custom/)\\\\n    *   [How to split by HTML header](https://python.langchain.com/v0.2/docs/how_to/HTML_header_metadata_splitter/)\\\\n    *   [How to split by HTML sections](https://python.langchain.com/v0.2/docs/how_to/HTML_section_aware_splitter/)\\\\n    *   [How to use the MultiQueryRetriever](https://python.langchain.com/v0.2/docs/how_to/MultiQueryRetriever/)\\\\n    *   [How to add scores to retriever results](https://python.langchain.com/v0.2/docs/how_to/add_scores_retriever/)\\\\n    *   [Caching](https://python.langchain.com/v0.2/docs/how_to/caching_embeddings/)\\\\n    *   [How to use callbacks in async environments](https://python.langchain.com/v0.2/docs/how_to/callbacks_async/)\\\\n    *   [How to attach callbacks to a runnable](https://python.langchain.com/v0.2/docs/how_to/callbacks_attach/)\\\\n    *   [How to propagate callbacks constructor](https://python.langchain.com/v0.2/docs/how_to/callbacks_constructor/)\\\\n    *   [How to pass callbacks in at runtime](https://python.langchain.com/v0.2/docs/how_to/callbacks_runtime/)\\\\n    *   [How to split by character](https://python.langchain.com/v0.2/docs/how_to/character_text_splitter/)\\\\n    *   [How to cache chat model responses](https://python.langchain.com/v0.2/docs/how_to/chat_model_caching/)\\\\n    *   [How to init any model in one line](https://python.langchain.com/v0.2/docs/how_to/chat_models_universal_init/)\\\\n    *   [How to track token usage in ChatModels](https://python.langchain.com/v0.2/docs/how_to/chat_token_usage_tracking/)\\\\n    *   [How to split code](https://python.langchain.com/v0.2/docs/how_to/code_splitter/)\\\\n    *   [How to do retrieval with contextual compression](https://python.langchain.com/v0.2/docs/how_to/contextual_compression/)\\\\n    *   [How to create custom callback handlers](https://python.langchain.com/v0.2/docs/how_to/custom_callbacks/)\\\\n    *   [How to create a custom chat model class](https://python.langchain.com/v0.2/docs/how_to/custom_chat_model/)\\\\n    *   [How to create a custom LLM class](https://python.langchain.com/v0.2/docs/how_to/custom_llm/)\\\\n    *   [Custom Retriever](https://python.langchain.com/v0.2/docs/how_to/custom_retriever/)\\\\n    *   [How to create custom tools](https://python.langchain.com/v0.2/docs/how_to/custom_tools/)\\\\n    *   [How to debug your LLM apps](https://python.langchain.com/v0.2/docs/how_to/debugging/)\\\\n    *   [How to load CSVs](https://python.langchain.com/v0.2/docs/how_to/document_loader_csv/)\\\\n    *   [How to load documents from a directory](https://python.langchain.com/v0.2/docs/how_to/document_loader_directory/)\\\\n    *   [How to load HTML](https://python.langchain.com/v0.2/docs/how_to/document_loader_html/)\\\\n    *   [How to load JSON](https://python.langchain.com/v0.2/docs/how_to/document_loader_json/)\\\\n    *   [How to load Markdown](https://python.langchain.com/v0.2/docs/how_to/document_loader_markdown/)\\\\n    *   [How to load Microsoft Office files](https://python.langchain.com/v0.2/docs/how_to/document_loader_office_file/)\\\\n    *   [How to load PDFs](https://python.langchain.com/v0.2/docs/how_to/document_loader_pdf/)\\\\n    *   [How to create a dynamic (self-constructing) chain](https://python.langchain.com/v0.2/docs/how_to/dynamic_chain/)\\\\n    *   [Text embedding models](https://python.langchain.com/v0.2/docs/how_to/embed_text/)\\\\n    *   [How to combine results from multiple retrievers](https://python.langchain.com/v0.2/docs/how_to/ensemble_retriever/)\\\\n    *   [How to select examples by length](https://python.langchain.com/v0.2/docs/how_to/example_selectors_length_based/)\\\\n    *   [How to select examples by maximal marginal relevance (MMR)](https://python.langchain.com/v0.2/docs/how_to/example_selectors_mmr/)\\\\n    *   [How to select examples by n-gram overlap](https://python.langchain.com/v0.2/docs/how_to/example_selectors_ngram/)\\\\n    *   [How to select examples by similarity](https://python.langchain.com/v0.2/docs/how_to/example_selectors_similarity/)\\\\n    *   [How to use reference examples when doing extraction](https://python.langchain.com/v0.2/docs/how_to/extraction_examples/)\\\\n    *   [How to handle long text when doing extraction](https://python.langchain.com/v0.2/docs/how_to/extraction_long_text/)\\\\n    *   [How to use prompting alone (no tool calling) to do extraction](https://python.langchain.com/v0.2/docs/how_to/extraction_parse/)\\\\n    *   [How to add fallbacks to a runnable](https://python.langchain.com/v0.2/docs/how_to/fallbacks/)\\\\n    *   [How to filter messages](https://python.langchain.com/v0.2/docs/how_to/filter_messages/)\\\\n    *   [Hybrid Search](https://python.langchain.com/v0.2/docs/how_to/hybrid/)\\\\n    *   [How to use the LangChain indexing API](https://python.langchain.com/v0.2/docs/how_to/indexing/)\\\\n    *   [How to inspect runnables](https://python.langchain.com/v0.2/docs/how_to/inspect/)\\\\n    *   [LangChain Expression Language Cheatsheet](https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/)\\\\n    *   [How to cache LLM responses](https://python.langchain.com/v0.2/docs/how_to/llm_caching/)\\\\n    *   [How to track token usage for LLMs](https://python.langchain.com/v0.2/docs/how_to/llm_token_usage_tracking/)\\\\n    *   [Run LLMs locally](https://python.langchain.com/v0.2/docs/how_to/local_llms/)\\\\n    *   [How to get log probabilities](https://python.langchain.com/v0.2/docs/how_to/logprobs/)\\\\n    *   [How to reorder retrieved results to mitigate the \\\\\"lost in the middle\\\\\" effect](https://python.langchain.com/v0.2/docs/how_to/long_context_reorder/)\\\\n    *   [How to split Markdown by Headers](https://python.langchain.com/v0.2/docs/how_to/markdown_header_metadata_splitter/)\\\\n    *   [How to merge consecutive messages of the same type](https://python.langchain.com/v0.2/docs/how_to/merge_message_runs/)\\\\n    *   [How to add message history](https://python.langchain.com/v0.2/docs/how_to/message_history/)\\\\n    *   [How to migrate from legacy LangChain agents to LangGraph](https://python.langchain.com/v0.2/docs/how_to/migrate_agent/)\\\\n    *   [How to retrieve using multiple vectors per document](https://python.langchain.com/v0.2/docs/how_to/multi_vector/)\\\\n    *   [How to pass multimodal data directly to models](https://python.langchain.com/v0.2/docs/how_to/multimodal_inputs/)\\\\n    *   [How to use multimodal prompts](https://python.langchain.com/v0.2/docs/how_to/multimodal_prompts/)\\\\n    *   [How to create a custom Output Parser](https://python.langchain.com/v0.2/docs/how_to/output_parser_custom/)\\\\n    *   [How to use the output-fixing parser](https://python.langchain.com/v0.2/docs/how_to/output_parser_fixing/)\\\\n    *   [How to parse JSON output](https://python.langchain.com/v0.2/docs/how_to/output_parser_json/)\\\\n    *   [How to retry when a parsing error occurs](https://python.langchain.com/v0.2/docs/how_to/output_parser_retry/)\\\\n    *   [How to parse XML output](https://python.langchain.com/v0.2/docs/how_to/output_parser_xml/)\\\\n    *   [How to parse YAML output](https://python.langchain.com/v0.2/docs/how_to/output_parser_yaml/)\\\\n    *   [How to use the Parent Document Retriever](https://python.langchain.com/v0.2/docs/how_to/parent_document_retriever/)\\\\n    *   [How to use LangChain with different Pydantic versions](https://python.langchain.com/v0.2/docs/how_to/pydantic_compatibility/)\\\\n    *   [How to add chat history](https://python.langchain.com/v0.2/docs/how_to/qa_chat_history_how_to/)\\\\n    *   [How to get a RAG application to add citations](https://python.langchain.com/v0.2/docs/how_to/qa_citations/)\\\\n    *   [How to do per-user retrieval](https://python.langchain.com/v0.2/docs/how_to/qa_per_user/)\\\\n    *   [How to get your RAG application to return sources](https://python.langchain.com/v0.2/docs/how_to/qa_sources/)\\\\n    *   [How to stream results from your RAG application](https://python.langchain.com/v0.2/docs/how_to/qa_streaming/)\\\\n    *   [How to split JSON data](https://python.langchain.com/v0.2/docs/how_to/recursive_json_splitter/)\\\\n    *   [How to recursively split text by characters](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/)\\\\n    *   [Response metadata](https://python.langchain.com/v0.2/docs/how_to/response_metadata/)\\\\n    *   [How to do \\\\\"self-querying\\\\\" retrieval](https://python.langchain.com/v0.2/docs/how_to/self_query/)\\\\n    *   [How to split text based on semantic similarity](https://python.langchain.com/v0.2/docs/how_to/semantic-chunker/)\\\\n    *   [How to chain runnables](https://python.langchain.com/v0.2/docs/how_to/sequence/)\\\\n    *   [How to save and load LangChain objects](https://python.langchain.com/v0.2/docs/how_to/serialization/)\\\\n    *   [How to split text by tokens](https://python.langchain.com/v0.2/docs/how_to/split_by_token/)\\\\n    *   [How to do question answering over CSVs](https://python.langchain.com/v0.2/docs/how_to/sql_csv/)\\\\n    *   [How to deal with large databases when doing SQL question-answering](https://python.langchain.com/v0.2/docs/how_to/sql_large_db/)\\\\n    *   [How to better prompt when doing SQL question-answering](https://python.langchain.com/v0.2/docs/how_to/sql_prompting/)\\\\n    *   [How to do query validation as part of SQL question-answering](https://python.langchain.com/v0.2/docs/how_to/sql_query_checking/)\\\\n    *   [How to stream runnables](https://python.langchain.com/v0.2/docs/how_to/streaming/)\\\\n    *   [How to stream responses from an LLM](https://python.langchain.com/v0.2/docs/how_to/streaming_llm/)\\\\n    *   [How to use a time-weighted vector store retriever](https://python.langchain.com/v0.2/docs/how_to/time_weighted_vectorstore/)\\\\n    *   [How to use a model to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)\\\\n    *   [How to pass run time values to a tool](https://python.langchain.com/v0.2/docs/how_to/tool_runtime/)\\\\n    *   [How to convert tools to OpenAI Functions](https://python.langchain.com/v0.2/docs/how_to/tools_as_openai_functions/)\\\\n    *   [How to handle tool errors](https://python.langchain.com/v0.2/docs/how_to/tools_error/)\\\\n    *   [How to add a human-in-the-loop for tools](https://python.langchain.com/v0.2/docs/how_to/tools_human/)\\\\n    *   [How to trim messages](https://python.langchain.com/v0.2/docs/how_to/trim_messages/)\\\\n    *   [How to create and query vector stores](https://python.langchain.com/v0.2/docs/how_to/vectorstores/)\\\\n*   [Conceptual guide](https://python.langchain.com/v0.2/docs/concepts/)\\\\n*   Ecosystem\\\\n    \\\\n    *   [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udee0\\\\ufe0f LangSmith](https://docs.smith.langchain.com/)\\\\n    *   [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udd78\\\\ufe0f LangGraph](https://langchain-ai.github.io/langgraph/)\\\\n    *   [\\\\ud83e\\\\udd9c\\\\ufe0f\\\\ud83c\\\\udfd3 LangServe](https://python.langchain.com/v0.2/docs/langserve/)\\\\n*   Versions\\\\n    \\\\n    *   [Overview](https://python.langchain.com/v0.2/docs/versions/overview/)\\\\n    *   [Release Policy](https://python.langchain.com/v0.2/docs/versions/release_policy/)\\\\n    *   [Packages](https://python.langchain.com/v0.2/docs/versions/packages/)\\\\n    *   [v0.2](https://python.langchain.com/v0.2/docs/versions/v0_2/)\\\\n        \\\\n        *   [LangChain v0.2](https://python.langchain.com/v0.2/docs/versions/v0_2/)\\\\n        *   [astream\\\\\\\\_events v2](https://python.langchain.com/v0.2/docs/versions/v0_2/migrating_astream_events/)\\\\n        *   [Changes](https://python.langchain.com/v0.2/docs/versions/v0_2/deprecations/)\\\\n*   [Security](https://python.langchain.com/v0.2/docs/security/)\\\\n\\\\n*   [](https://python.langchain.com/v0.2/)\\\\n*   Introduction\\\\n\\\\nOn this page\\\\n\\\\nIntroduction\\\\n============\\\\n\\\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\\\n\\\\nLangChain simplifies every stage of the LLM application lifecycle:\\\\n\\\\n*   **Development**: Build your applications using LangChain\\'s open-source [building blocks](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel) and [components](https://python.langchain.com/v0.2/docs/concepts/). Hit the ground running using [third-party integrations](https://python.langchain.com/v0.2/docs/integrations/platforms/) and [Templates](https://python.langchain.com/v0.2/docs/templates/).\\\\n*   **Productionization**: Use [LangSmith](https://docs.smith.langchain.com/) to inspect, monitor and evaluate your chains, so that you can continuously optimize and deploy with confidence.\\\\n*   **Deployment**: Turn any chain into an API with [LangServe](https://python.langchain.com/v0.2/docs/langserve/).\\\\n\\\\n![Image 2: Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.](https://python.langchain.com/v0.2/svg/langchain_stack.svg)Concretely, the framework consists of the following open-source libraries:\\\\n\\\\n*   **`langchain-core`**: Base abstractions and LangChain Expression Language.\\\\n*   **`langchain-community`**: Third party integrations.\\\\n    *   Partner packages (e.g. **`langchain-openai`**, **`langchain-anthropic`**, etc.): Some integrations have been further split into their own lightweight packages that only depend on **`langchain-core`**.\\\\n*   **`langchain`**: Chains, agents, and retrieval strategies that make up an application\\'s cognitive architecture.\\\\n*   **[LangGraph](https://langchain-ai.github.io/langgraph)**: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\\\\n*   **[LangServe](https://python.langchain.com/v0.2/docs/langserve/)**: Deploy LangChain chains as REST APIs.\\\\n*   **[LangSmith](https://docs.smith.langchain.com/)**: A developer platform that lets you debug, test, evaluate, and monitor LLM applications.\\\\n\\\\nnote\\\\n\\\\nThese docs focus on the Python LangChain library. [Head here](https://js.langchain.com/) for docs on the JavaScript LangChain library.\\\\n\\\\n[Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#tutorials \\\\\"Direct link to tutorials\\\\\")\\\\n------------------------------------------------------------------------------------------------------------------------------------------------------------\\\\n\\\\nIf you\\'re looking to build something specific or are more of a hands-on learner, check out our [tutorials](https://python.langchain.com/v0.2/docs/tutorials/). This is the best place to get started.\\\\n\\\\nThese are the best ones to get started with:\\\\n\\\\n*   [Build a Simple LLM Application](https://python.langchain.com/v0.2/docs/tutorials/llm_chain/)\\\\n*   [Build a Chatbot](https://python.langchain.com/v0.2/docs/tutorials/chatbot/)\\\\n*   [Build an Agent](https://python.langchain.com/v0.2/docs/tutorials/agents/)\\\\n\\\\nExplore the full list of tutorials [here](https://python.langchain.com/v0.2/docs/tutorials/).\\\\n\\\\n[How-to guides](https://python.langchain.com/v0.2/docs/how_to/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#how-to-guides \\\\\"Direct link to how-to-guides\\\\\")\\\\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------\\\\n\\\\n[Here](https://python.langchain.com/v0.2/docs/how_to/) you\\\\u2019ll find short answers to \\\\u201cHow do I\\\\u2026.?\\\\u201d types of questions. These how-to guides don\\\\u2019t cover topics in depth \\\\u2013 you\\\\u2019ll find that material in the [Tutorials](https://python.langchain.com/v0.2/docs/tutorials/) and the [API Reference](https://api.python.langchain.com/en/latest/). However, these guides will help you quickly accomplish common tasks.\\\\n\\\\n[Conceptual guide](https://python.langchain.com/v0.2/docs/concepts/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#conceptual-guide \\\\\"Direct link to conceptual-guide\\\\\")\\\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\\\n\\\\nIntroductions to all the key parts of LangChain you\\\\u2019ll need to know! [Here](https://python.langchain.com/v0.2/docs/concepts/) you\\'ll find high level explanations of all LangChain concepts.\\\\n\\\\n[API reference](https://api.python.langchain.com/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#api-reference \\\\\"Direct link to api-reference\\\\\")\\\\n--------------------------------------------------------------------------------------------------------------------------------------------------------\\\\n\\\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\\\n\\\\nEcosystem[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#ecosystem \\\\\"Direct link to Ecosystem\\\\\")\\\\n-------------------------------------------------------------------------------------------------------\\\\n\\\\n### [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udee0\\\\ufe0f LangSmith](https://docs.smith.langchain.com/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#%EF%B8%8F-langsmith \\\\\"Direct link to \\\\ufe0f-langsmith\\\\\")\\\\n\\\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\\\n\\\\n### [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udd78\\\\ufe0f LangGraph](https://langchain-ai.github.io/langgraph)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#%EF%B8%8F-langgraph \\\\\"Direct link to \\\\ufe0f-langgraph\\\\\")\\\\n\\\\nBuild stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain primitives.\\\\n\\\\n### [\\\\ud83e\\\\udd9c\\\\ud83c\\\\udfd3 LangServe](https://python.langchain.com/v0.2/docs/langserve/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#-langserve \\\\\"Direct link to -langserve\\\\\")\\\\n\\\\nDeploy LangChain runnables and chains as REST APIs.\\\\n\\\\nAdditional resources[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#additional-resources \\\\\"Direct link to Additional resources\\\\\")\\\\n----------------------------------------------------------------------------------------------------------------------------------------\\\\n\\\\n### [Security](https://python.langchain.com/v0.2/docs/security/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#security \\\\\"Direct link to security\\\\\")\\\\n\\\\nRead up on our [Security](https://python.langchain.com/v0.2/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\\\n\\\\n### [Integrations](https://python.langchain.com/v0.2/docs/integrations/providers/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#integrations \\\\\"Direct link to integrations\\\\\")\\\\n\\\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of [integrations](https://python.langchain.com/v0.2/docs/integrations/providers/).\\\\n\\\\n### [Contributing](https://python.langchain.com/v0.2/docs/contributing/)[\\\\u200b](https://python.langchain.com/v0.2/docs/introduction/#contributing \\\\\"Direct link to contributing\\\\\")\\\\n\\\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\\\n\\\\n[Edit this page](https://github.com/langchain-ai/langchain/edit/master/docs/docs/introduction.mdx)\\\\n\\\\n* * *\\\\n\\\\n#### Was this page helpful?\\\\n\\\\n  \\\\n\\\\n#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchain/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CIssue+related+to+/v0.2/docs/introduction/%3E&url=https://python.langchain.com/v0.2/docs/introduction/).\\\\n\\\\n[Next Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\\\\n\\\\n*   [Tutorials](https://python.langchain.com/v0.2/docs/introduction/#tutorials)\\\\n*   [How-to guides](https://python.langchain.com/v0.2/docs/introduction/#how-to-guides)\\\\n*   [Conceptual guide](https://python.langchain.com/v0.2/docs/introduction/#conceptual-guide)\\\\n*   [API reference](https://python.langchain.com/v0.2/docs/introduction/#api-reference)\\\\n*   [Ecosystem](https://python.langchain.com/v0.2/docs/introduction/#ecosystem)\\\\n    *   [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udee0\\\\ufe0f LangSmith](https://python.langchain.com/v0.2/docs/introduction/#%EF%B8%8F-langsmith)\\\\n    *   [\\\\ud83e\\\\udd9c\\\\ud83d\\\\udd78\\\\ufe0f LangGraph](https://python.langchain.com/v0.2/docs/introduction/#%EF%B8%8F-langgraph)\\\\n    *   [\\\\ud83e\\\\udd9c\\\\ud83c\\\\udfd3 LangServe](https://python.langchain.com/v0.2/docs/introduction/#-langserve)\\\\n*   [Additional resources](https://python.langchain.com/v0.2/docs/introduction/#additional-resources)\\\\n    *   [Security](https://python.langchain.com/v0.2/docs/introduction/#security)\\\\n    *   [Integrations](https://python.langchain.com/v0.2/docs/introduction/#integrations)\\\\n    *   [Contributing](https://python.langchain.com/v0.2/docs/introduction/#contributing)\\\\n\\\\nCommunity\\\\n\\\\n*   [Discord](https://discord.gg/cU2adEyC7w)\\\\n*   [Twitter](https://twitter.com/LangChainAI)\\\\n\\\\nGitHub\\\\n\\\\n*   [Organization](https://github.com/langchain-ai)\\\\n*   [Python](https://github.com/langchain-ai/langchain)\\\\n*   [JS/TS](https://github.com/langchain-ai/langchainjs)\\\\n\\\\nMore\\\\n\\\\n*   [Homepage](https://langchain.com/)\\\\n*   [Blog](https://blog.langchain.dev/)\\\\n*   [YouTube](https://www.youtube.com/@LangChain)\\\\n\\\\nCopyright \\\\u00a9 2024 LangChain, Inc.\"}, {\"title\": \"Marketo Forms 2 Cross Domain request proxy frame\", \"link\": \"https://www.datastax.com/guides/what-is-langchain\", \"snippet\": \"LangChain is <strong>a Python framework designed to streamline AI application development, focusing on real-time data processing and integration with Large Language Models (LLMs).</strong> It offers features for data communication, generation of vector embeddings, and simplifies the interaction with LLMs, making ...\", \"content\": \"This page is used by Marketo Forms 2 to proxy cross domain AJAX requests.\\\\n-------------------------------------------------------------------------\"}, {\"title\": \"What Is LangChain: Components, Benefits & How to Get Started\", \"link\": \"https://lakefs.io/blog/what-is-langchain-ml-architecture/\", \"snippet\": \"LangChain is <strong>an open-source framework that gives developers the tools they need to create applications using large language models (LLMs).</strong> In its essence, LangChain is a prompt orchestration tool that makes it easier for teams to connect various prompts interactively.\", \"content\": \"LangChain is one of the most useful frameworks for developers looking to create LLM-powered applications. It allows LLM models to create replies based on the most up-to-date data accessible online and simplifies the process of arranging vast volumes of data so that LLMs can quickly access it.\\\\n\\\\nThis is how LangChain enables developers to build dynamic, data-responsive applications. The open-source framework has so far enabled developers to create some pretty advanced AI chatbots, generative question-answering (GQA) systems, and language summarization tools ([you can find some examples here](https://lablab.ai/apps/tech/langchain)).\\\\n\\\\nIn this article, we dive into LangChain in detail to show you how it works, what developers can build with it, and more.\\\\n\\\\nLangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). In its essence, LangChain is a prompt orchestration tool that makes it easier for teams to connect various prompts interactively.\\\\n\\\\nLangChain began as an open source project, but as the GitHub stars piled up, it was quickly turned into a company led by Harrison Chase.\\\\n\\\\nLLMs (such as GPT3 or GPT4) give a completion for a single prompt, which is more or less like receiving a complete result for a single request. For example, you could tell the LLM to \\\\u201ccreate a sculpture,\\\\u201d and it would do it. You may also provide more sophisticated requests, such as \\\\u201ccreate a sculpture of an axolotl at the bottom of a lake.\\\\u201d The LLM will likely return what you wanted.\\\\n\\\\nBut what if you asked this instead:\\\\n\\\\n**\\\\u201cGive me the step by step instructions to carving an axolotl sculpture out of wood\\\\u201d?**\\\\n\\\\nTo avoid having the user explicitly provide every single step and choose the sequence of execution, you can use LLMs to produce the next step at each point, utilizing the prior step results as its context.\\\\n\\\\nThe LangChain framework can do that for you. It arranges a succession of prompts to reach a desired result. It provides a simple interface for developers to interact with LLMs. That way, you could say that LangChain works like a reductionist wrapper for leveraging LLMs.\\\\n\\\\nWhat is LangChain Expression Language?\\\\n--------------------------------------\\\\n\\\\nLangChain Expression Language (LCEL) is a declarative language that helps engineers connect chains easily. It was built from the start to facilitate placing prototypes in production with no code modifications.\\\\n\\\\nHere are a few benefits of LCEL:\\\\n\\\\n*   When you use LCEL to create your chains, you get the best potential time-to-first-token (the amount of time it takes for the first piece of output to appear). For some chains, this means that we stream tokens directly from an LLM to a streaming output parser, and you get back parsed, incremental chunks of output at the same pace as the LLM provider.\\\\n*   Any chain generated with LCEL may be called using both the synchronous API (for example, in a Jupyter notebook when experimenting) and the asynchronous API (like a LangServe server). This allows for the use of the same code for prototypes and production, with excellent speed and the flexibility to handle several concurrent requests on the same server.\\\\n*   A data scientist or practitioner can have steps in LCEL chains executed in parallel.\\\\n*   LangServe can quickly deploy any chain generated using LCEL.\\\\n\\\\nWhy consider using LangChain?\\\\n-----------------------------\\\\n\\\\nWhen employed with a single prompt, LLMs are already quite strong. However, what they do is essentially perform completions by predicting the most likely next word. They don\\\\u2019t think and reason like people do before they say something or respond. At least that\\\\u2019s what we like to believe.\\\\n\\\\nReasoning is the process of using information acquired prior to the communication act in order to reach new conclusions. We don\\\\u2019t consider creating an axolotl sculpture as a single continuous operation but rather as a succession of smaller actions that impact the next steps.\\\\n\\\\nLangChain is a framework that allows developers to create agents capable of reasoning about issues and breaking them down into smaller sub-tasks. By building intermediary stages and chaining complex commands together, you can add context and memory to completions using LangChain.\\\\n\\\\n### Here\\\\u2019s an example of LangChain usage with Large Language Models\\\\n\\\\nIf you ask an LLM which branches were top performers in your chain of art supply stores, here\\\\u2019s what\\\\u2019s going to happen:\\\\n\\\\nThe model will build a logical SQL query to retrieve the results and serve you a bunch of fictitious but entirely plausible column names.\\\\n\\\\nWhat would that look like if you used LangChain?\\\\n\\\\nIn this scenario, you could provide the LLM with a bunch of functions to use and then ask it to create a process for you. Then, after going through that process, you might get a single answer:\\\\n\\\\n\\\\u201c**Art supply store #1516 in Dallas is your top-performing store.**\\\\u201c\\\\n\\\\nNote that some work needs to go into the formulation of the SQL query.\\\\n\\\\nYou can start by writing some functions like getTables() or getSchema(table). But how do you get the table schema if you don\\\\u2019t know the table names? Which of the table schemas includes data about sales per store anyway?\\\\n\\\\nUsing LangChain, developers can rely on LLMs to produce each step and ask each of these questions. So, you no longer need to spend time providing input and manually organizing these phases.\\\\n\\\\nWhy is LangChain captivating the industry?\\\\n------------------------------------------\\\\n\\\\nLangChain is fascinating because it lets teams augment existing LLMs with memory and context. They can artificially add \\\\u201creasoning\\\\u201d and complete more complex tasks with greater precision and accuracy.\\\\n\\\\nDevelopers are excited about LangChain because it offers a new approach to creating user interfaces \\\\u2013 where users can just ask for what they want rather than dragging and dropping elements or using code.\\\\n\\\\nConsider a tool we\\\\u2019ve all used at some point: Microsoft PowerPoint. Take a look at the sheer number of buttons, each of which performs a specific job. Nobody would mind using natural language to describe exactly what they need and get a neat presentation style in a matter of seconds.\\\\n\\\\nThis explains the massive success of ChatGPT. It\\\\u2019s way more than a basic implementation of GPT. Its output comes from constant learning via a feedback loop. When a coding request is made, ChatGPT formalizes the request, presents two implementations, gives the reasoning for each, and explains the code.\\\\n\\\\nGiven that there is no method to describe the code before it was created by the LLM, the LLM completion to explain the code must have come to life after it was formed.\\\\n\\\\nHow LangChain works\\\\n-------------------\\\\n\\\\nLangChain was developed in Python and JavaScript, and it supports a wide range of language models such as GPT3, Hugging Face, Jurassic-1 Jumbo, and others.\\\\n\\\\nTo start using LangChain, you must first create a language model. This means either taking advantage of a publicly available language model, such as GPT3, or training your own model.\\\\n\\\\nOnce completed, you can start developing applications with LangChain. LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications.\\\\n\\\\nIt creates a workflow by chaining together a sequence of components called links. Each link in the chain does something specific, such as:\\\\n\\\\n*   Formatting of user input\\\\n*   Using a data source\\\\n*   Referring to a linguistic model\\\\n*   Processing the language model\\\\u2019s output\\\\n\\\\nThe links in a chain are connected in a sequential manner, with the output of one link serving as the input to the next. By chaining together small operations, the chain is able to do more complicated tasks.\\\\n\\\\nWhat are the fundamental components of LangChain?\\\\n-------------------------------------------------\\\\n\\\\n### LLMs\\\\n\\\\nNaturally, LangChain calls for LLMs \\\\u2013 large language models that are trained on vast text and code datasets. You can use them to generate text, translate languages, and answer queries, among other things.\\\\n\\\\n![Image 1: LangChain calls for LLMs](https://cdn-kfpfp.nitrocdn.com/LPJTcQItTfFXIvmLmluGDpHNkMGCVcPt/assets/images/optimized/rev-0873aab/lakefs.io/wp-content/uploads/2023/11/image.png)\\\\n\\\\nSource: [LangChain documentation](https://python.langchain.com/docs/modules/model_io/)\\\\n\\\\n### Prompt templates\\\\u00a0\\\\n\\\\nPrompt templates are used to format user input so that the language model can understand it. You can use them to provide context for the user\\\\u2019s input or to describe the job that the language model should complete. A prompt template for a chatbot, for example, can include the user\\\\u2019s name and question.\\\\n\\\\n### Indexes\\\\n\\\\nIndexes are databases that hold information about the training data for the LLM. This data can comprise the text of the documents, their metadata, and their connections.\\\\n\\\\n### Retrievers\\\\n\\\\nRetrievers are algorithms that look for specific information in an index. You can use them to locate documents that are relevant to a user\\\\u2019s query or documents that are most similar to a particular file. Retrievers are critical for increasing the LLM\\\\u2019s response speed and accuracy.\\\\n\\\\n### Output parsers\\\\u00a0\\\\n\\\\nLLM output parsers are in charge of formatting the replies they generate. They can adjust the structure of the response, eliminate undesired stuff, or add extra information. Output parsers are key to ensuring that the LLM\\\\u2019s replies are simple to interpret and apply.\\\\n\\\\n### Vector store\\\\n\\\\n![Image 2: Vector stores](https://cdn-kfpfp.nitrocdn.com/LPJTcQItTfFXIvmLmluGDpHNkMGCVcPt/assets/images/optimized/rev-0873aab/lakefs.io/wp-content/uploads/2023/11/image-1.png)\\\\n\\\\nSource: [LangChain documentation](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\\\\n\\\\nA vector store houses mathematical representations of words and phrases. It comes in handy for tasks like answering questions and summarizing. A [vector database](https://lakefs.io/blog/what-is-vector-databases/), for example, can be used to locate all words that are comparable to the word \\\\u201ccat.\\\\u201d\\\\n\\\\n### Agents\\\\n\\\\nAgents are programs that can reason about issues and divide them into smaller subtasks. You can use an agent to direct the flow of a chain and decide which jobs to do \\\\u2013 for example, assess whether a language model or a human expert is best suited to answer a user\\\\u2019s inquiry.\\\\n\\\\n8 benefits of using LangChain\\\\n-----------------------------\\\\n\\\\n1.  **Scalability** \\\\u2013 LangChain may be used to create applications capable of handling massive volumes of data.\\\\n2.  **Adaptability** \\\\u2013 The framework\\\\u2019s adaptability allows it to be used to develop a wide range of applications, from chatbots to question-answering systems.\\\\n3.  **Extensibility** \\\\u2013 Developers may add their own features and functionality to the framework because it is expandable.\\\\n4.  **Ease of use** \\\\u2013 LangChain offers a high-level API for connecting language models to various data sources and building complicated applications.\\\\n5.  **Open source** \\\\u2013\\\\u00a0 LangChain is an open-source framework that is free to use and modify.\\\\n6.  **Vibrant community** \\\\u2013 There is a huge and active community of LangChain users and developers that can assist and support you.\\\\n7.  **Great documentation** \\\\u2013 The documentation is thorough and simple to understand.\\\\n8.  **Integrations** \\\\u2013 LangChain may be integrated with various frameworks and libraries, such as Flask and TensorFlow.\\\\n\\\\nHow to get started with LangChain\\\\n---------------------------------\\\\n\\\\nLangChain\\\\u2019s source code is accessible on [GitHub](https://github.com/langchain-ai/langchain). You can download and install the source code on your machine.\\\\n\\\\nLangChain is also available as a Docker image, making it simple to install on cloud platforms.\\\\n\\\\nYou can also install it with a simple pip command in Python: langchain install pip\\\\n\\\\nIf you want to install all of LangChain\\\\u2019s integration requirements, use the following command: pip install langchain\\\\\\\\[all\\\\\\\\]\\\\n\\\\n**Now you\\\\u2019re ready to start a new project!**\\\\n\\\\n1.  Create a new directory and run the following command: init langchain\\\\n2.  Next, you need to import the required modules and make a chain, which is a series of links where each performs a certain function.\\\\u00a0\\\\n3.  To make a chain, create an instance of the Chain class and then add links to it. Here\\\\u2019s a snippet that generates a chain that calls a language model and receives its response: Chain() returns a chain.add\\\\\\\\_link(Link(model=\\\\u201dopenai\\\\u201d, prompt=\\\\u201dCreate an axolotl sculpture\\\\u201d)\\\\n4.  To execute a chain, use the run() function on the chain object.\\\\u00a0\\\\n5.  The output of a chain is the output of the chain\\\\u2019s last link. To get the chain\\\\u2019s output, use the get\\\\\\\\_output() function on the chain object.\\\\n6.  Finally, you can personalize the chain by changing the properties of links or adding/removing them.\\\\n\\\\nWhat kind of apps can you build with LangChain?\\\\n-----------------------------------------------\\\\n\\\\n### Content generation and summarization\\\\n\\\\nLangChain comes in handy for creating summarizing systems capable of producing summaries of news articles, blog entries, and other sorts of text. Another common use case is content generators that generate writing that is both helpful and interesting.\\\\n\\\\n### Chatbots\\\\n\\\\nNaturally, chatbots or any other system that responds to questions is a great use case for LangChain. Such systems will be able to access and process data from a range of sources, such as databases, APIs, and the internet. Chatbots can respond to queries, provide customer support, or even generate unique text formats such as poetry, code, screenplays, musical pieces, email, letters, and so on.\\\\n\\\\n### Data analysis software\\\\n\\\\nLangChain can also be used to create data analysis tools that assist users in understanding the links between various data pieces.\\\\n\\\\nIs LangChain open-source?\\\\n-------------------------\\\\n\\\\nYes, LangChain is an open-source project that is entirely free to use. You can get the source code from [GitHub](https://github.com/langchain-ai/langchain) and use it to create your own apps. Also, you can use [pre-trained models provided by LangChain](https://python.langchain.com/docs/integrations/text_embedding).\\\\n\\\\nWrap up: the future of LangChain\\\\n--------------------------------\\\\n\\\\nThe primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called \\\\u201cchat interfaces.\\\\u201d In [a recent interview](https://www.youtube.com/watch?v=zaYTXQFR0_s&ab_channel=TheFullStack), the company\\\\u2019s CEO Harrison Chase, said the ideal use case right now is a \\\\u201cchat over your documents.\\\\u201d LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.\\\\n\\\\nHe also hinted at the future evolution of such interfaces:\\\\n\\\\n> _\\\\u201cLong term, there\\\\u2019s probably better UX\\\\u2019s than chat. But I think at the moment that\\\\u2019s the immediate thing that you can stand up super-easily, without a lot of extra work. In six months, do I expect chat to be the best UX? Probably not. But I think right now, what\\\\u2019s the thing that you can build at the moment to deliver value, it\\\\u2019s probably that \\\\\\\\[i.e. chat\\\\\\\\].\\\\u201d_\\\\n\\\\nIn the future, we might see teams developing applications powered by LangChain for other areas. Given the novelty of designing apps with LLMs, frameworks like LangChain are indispensable for providing tools to help address some of the challenges with LLMs in the data science world. Install LangChain and see what it can do for yourself.\\\\n\\\\n*   [What is LangChain?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#what-is-langchain \\\\\"What is LangChain?\\\\\")\\\\n*   [What is LangChain Expression Language?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#what-is-langchain-expression-language \\\\\"What is LangChain Expression Language?\\\\\")\\\\n*   [Why consider using LangChain?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#why-consider-using-langchain \\\\\"Why consider using LangChain?\\\\\")\\\\n*   [Why is LangChain captivating the industry?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#why-is-langchain-captivating-the-industry \\\\\"Why is LangChain captivating the industry?\\\\\")\\\\n*   [How LangChain works](https://lakefs.io/blog/what-is-langchain-ml-architecture/#how-langchain-works \\\\\"How LangChain works\\\\\")\\\\n*   [What are the fundamental components of LangChain?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#what-are-the-fundamental-components-of-langchain \\\\\"What are the fundamental components of LangChain?\\\\\")\\\\n*   [8 benefits of using LangChain](https://lakefs.io/blog/what-is-langchain-ml-architecture/#8-benefits-of-using-langchain \\\\\"8 benefits of using LangChain\\\\\")\\\\n*   [How to get started with LangChain](https://lakefs.io/blog/what-is-langchain-ml-architecture/#how-to-get-started-with-langchain \\\\\"How to get started with LangChain\\\\\")\\\\n*   [What kind of apps can you build with LangChain?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#what-kind-of-apps-can-you-build-with-langchain \\\\\"What kind of apps can you build with LangChain?\\\\\")\\\\n*   [Is LangChain open-source?](https://lakefs.io/blog/what-is-langchain-ml-architecture/#is-langchain-open-source \\\\\"Is LangChain open-source?\\\\\")\\\\n*   [Wrap up: the future of LangChain](https://lakefs.io/blog/what-is-langchain-ml-architecture/#wrap-up-the-future-of-langchain \\\\\"Wrap up: the future of LangChain\\\\\")\\\\n\\\\n![Image 3](https://cdn-kfpfp.nitrocdn.com/LPJTcQItTfFXIvmLmluGDpHNkMGCVcPt/assets/images/optimized/rev-0873aab/lakefs.io/wp-content/uploads/2023/10/image-44.png)\\\\n\\\\n*   [](https://www.linkedin.com/in/idan-novogroder-a636512b9/)\\\\n\\\\nIdan has an extensive background in software and DevOps engineering. He is passionate about tackling real-life coding and system design challenges. As a key contributor, Idan played a significant role in launching, maintaining, and shaping lakeFS Cloud, which is a fully-managed solution offered by lakeFS. In his free time, Idan enjoys playing basketball, hiking in beautiful nature reserves, and scuba diving in coral reefs.\"}]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"what is langchain?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
